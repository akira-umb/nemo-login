#!/usr/bin/python3

#Author: Dustin Olley dolley@som.umaryland.edu

# Creating the input_file:
#   1) In Neo4j run the following cypher:
#       MATCH(f:file) WHERE EXISTS(f.https) RETURN f.id as file_id, f.https as file_url
#   2) Click 'Export CSV'


## Cypher Queries to create http URLs from fasp URLs (for iHMP file nodes)

## Should return count = 35598
# MATCH(file:file)-[:derived_from]->(sample:sample)-[:extracted_from]->(subject:subject{project_subtype: "ihmp"}) 
# WHERE EXISTS(file.fasp) AND NOT EXISTS(file.http) AND NOT EXISTS(file.https) AND NOT EXISTS(file.ftp) AND NOT EXISTS(file.s3) AND NOT EXISTS(file.gs)
# AND file.fasp CONTAINS 'fasp://aspera.ihmpdcc.org/'
# SET file.http = replace(file.fasp, "fasp://aspera.ihmpdcc.org/", "http://downloads.hmpdacc.org/ihmp/")
# RETURN COUNT(file)

## Should return count = 25290
# MATCH(file:file)-[:derived_from]->(sample:sample)-[:extracted_from]->(subject:subject{project_subtype: "ihmp"}) 
# WHERE EXISTS(file.fasp) AND NOT EXISTS(file.http) AND NOT EXISTS(file.https) AND NOT EXISTS(file.ftp) AND NOT EXISTS(file.s3) AND NOT EXISTS(file.gs)
# AND file.fasp CONTAINS 'fasp://aspera2.ihmpdcc.org/'
# SET file.http = replace(file.fasp, "fasp://aspera2.ihmpdcc.org/", "http://downloads.hmpdacc.org/ihmp/")
# RETURN COUNT(file)

# Confirm that all iHMP file nodes with a FASP do not lack an HTTP URL - Should return 0
# MATCH(file:file)-[:derived_from]->(sample:sample)-[:extracted_from]->(subject:subject{project_subtype: "ihmp"}) 
# WHERE EXISTS(file.fasp) AND NOT EXISTS(file.http) AND NOT EXISTS(file.https) AND NOT EXISTS(file.ftp) AND NOT EXISTS(file.s3) AND NOT EXISTS(file.gs)
# RETURN COUNT(file)

import argparse
import os
import requests

OUTPUT_FILE = "http_status_code_errors.tsv"

def main():
    '''
    Makes an HTTP HEAD request to a URL. If the status code returned does not equal 200, the file id, url, and status are logged in an output file

    Takes a CSV file with 2 columns as shown in the below example. The file can be generated by exporting the results of a query via the Neo4j browser UI.

    -i, --input_file (exported from Neo4j browser):
        file_id,file_http
        745297f7a7f28d0d15d5060e7bfef3df,http://downloads.hmpdacc.org/ihmp/ptb/genome/microbiome/16s/hm16str/EP624102_K10_MV1D.trimmedseqset.fasta.gz
        ...

    -o, --output_file containing file IDs and file urls where the returned status code was not 200: 
        file_id	file_url	status_code
        634416dfd8b630dcc6bba6aec4757aa5	http://downloads.hmpdacc.org/ihmp/t2d/genome/microbiome/16s/raw/HMP2_J45279_1_ST_T0_B0_0120_ZVBQY1N-6024_APATM.raw.fastq.tar	404
        ...

    '''

    parser = argparse.ArgumentParser( description='Given a file containing two comma-separated columns: file ids and file http urls, make HTTP Heads Requests to each url')
    parser.add_argument('-i', '--input_file', type=str, required=True, help='Path to an input file' )
    parser.add_argument('-o', '--output_file', type=str, required=False, help='Name of the error output file' )
    args = parser.parse_args()

    count_total = 0
    count_errors = 0
    errors = []
    with open(args.input_file, 'r') as fh:
        lines = fh.readlines()
        for line in lines:
            line = line.strip()
            if not '://' in line:
                # skip anyline (includes 1st line) lacking '//' in http://
                continue

            cols = line.split(',')
            file_id = cols[0]
            url = cols[1]

            try:
                print("validating url: {}".format(url))
                response = requests.head(url)
                if response.status_code != 200:
                    print("...status code is not 200. Recording error.")
                    errors.append({'file_id': file_id,
                                'file_url': url,
                                'status_code': response.status_code
                                })
                    count_errors += 1
                else:
                    print("...status code 200. Success!")
            except:
                errors.append({'file_id': file_id,
                            'file_url': url,
                            'status_code': 'None. Failed before request was made'
                            })
                count_errors += 1

            count_total += 1

    print("\nFinished\n")
    print("Total URLs tested: {}".format(str(count_total)))
    print("Total URLs did not return status code 200: {}".format(str(count_errors)))
    if len(errors) > 0:

        error_file_name = args.output_file if args.output_file else OUTPUT_FILE

        dir_path = os.path.dirname(os.path.realpath(__file__))
        error_filepath = os.path.join(dir_path, error_file_name)
        print("Errors recorded as output to file: {}".format(error_filepath))
        with open(error_filepath, 'w') as fo:
            fo.write("file_id\tfile_url\tstatus_code\n")
            for error in errors:
                fo.write(str(error['file_id']) + "\t" + str(error['file_url']) + "\t" + str(error['status_code']) + "\n")


if __name__ == "__main__":
    main()

